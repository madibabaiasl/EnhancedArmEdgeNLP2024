# Enhanced Robot Arm at the Edge with NLP and Vision Systems

This repository houses the code and data for our project that integrates edge computing, Natural Language Processing (NLP), and computer vision to create an enhanced robot arm system. Our work demonstrates a new approach to assistive robotics, leveraging the power of large language models (LLMs) alongside advanced vision systems to interpret and execute complex commands conveyed through natural language. This project aims to improve the intuitiveness, responsiveness, and accessibility of robotic systems, making them more adaptable to the nuanced needs of users, especially those with disabilities.

## Dependencies 

## Usage

To use the system, follow these steps:

- System Setup and Configuration: Ensure the robotic arm and vision system are correctly set up and connected to your computing environment. Adjust the system configuration files to match your setup, including ROS (Robot Operating System) commands and vision system parameters. A complete guide can be found here: https://github.com/madibabaiasl/modern-robotics-course
- Execution: 

## Example Results 


<p align="center">
  <a href="https://github.com/madibabaiasl/IROS2024/assets/118206851/c01d0b9a-b602-4a32-9539-784c1b50063e">
    <img src="URL_TO_ICON_1" alt="Video 1" width="100" /> <!-- Adjust width as needed -->
  </a>
  <a href="https://github.com/madibabaiasl/IROS2024/assets/118206851/c01d0b9a-b602-4a32-9539-784c1b50063e">
    <img src="URL_TO_ICON_2" alt="Video 2" width="100" /> <!-- Adjust width as needed -->
  </a>
  <a href="[URL_TO_VIDEO_3](https://github.com/madibabaiasl/IROS2024/assets/118206851/c01d0b9a-b602-4a32-9539-784c1b50063e)">
    <img src="URL_TO_ICON_3" alt="Video 3" width="100" /> <!-- Adjust width as needed -->
  </a>
</p>




